# Ollama Setup f√ºr Zenith Finance

## üöÄ Automatische PDF-Auslesung mit KI

Ollama erm√∂glicht deutlich bessere und genauere Extraktion von Bankdaten aus PDFs durch lokale KI-Modelle.

### Installation

1. **Ollama herunterladen**
   ```bash
   # macOS
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # Oder manuell von https://ollama.ai
   ```

2. **Modell installieren**
   ```bash
   # Empfohlenes Modell f√ºr strukturierte Daten (klein und schnell)
   ollama pull qwen2.5
   
   # Alternative: Llama 3.2 (gr√∂√üer, aber sehr gut)
   ollama pull llama3.2
   
   # Kleines Modell f√ºr schw√§chere Hardware
   ollama pull phi3
   ```

3. **Ollama starten**
   ```bash
   ollama serve
   ```

4. **App neu starten**
   - Starte `npm run dev` neu
   - Die App erkennt automatisch verf√ºgbare Modelle

### Wie es funktioniert

- **Prim√§r**: KI analysiert PDF-Text und extrahiert strukturierte Daten
- **Fallback**: Bei Fehlern wird der regelbasierte Parser verwendet
- **Lokal**: Alle Daten bleiben auf deinem Computer
- **Kostenlos**: Keine API-Kosten

### Vorteile

‚úÖ **Bessere Genauigkeit** - Versteht komplexe PDF-Layouts  
‚úÖ **Merchant-Namen** - Extrahiert saubere Gesch√§ftsnamen  
‚úÖ **Flexible Formate** - Funktioniert mit verschiedenen Banken  
‚úÖ **Datenschutz** - Alles l√§uft lokal  
‚úÖ **Kostenlos** - Keine API-Geb√ºhren  

### System-Anforderungen

- **RAM**: Mindestens 8GB (16GB empfohlen)
- **Speicher**: 2-4GB f√ºr Modelle
- **CPU**: Moderne CPU (Apple Silicon ideal)

### Troubleshooting

**Ollama l√§uft nicht?**
```bash
# Status pr√ºfen
ollama list

# Neu starten
ollama serve
```

**Modell nicht gefunden?**
```bash
# Verf√ºgbare Modelle anzeigen
ollama list

# Modell neu installieren
ollama pull qwen2.5
```

**Performance-Probleme?**
- Verwende `phi3` f√ºr kleinere Hardware
- Stelle sicher, dass genug RAM verf√ºgbar ist
- Schlie√üe andere ressourcenintensive Apps